{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjMd6T7wgaTg",
        "outputId": "f0c4c815-3f53-46c7-db34-44f5d82ba151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mujoco\n",
            "  Downloading mujoco-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.37.2)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (26.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.13.0)\n",
            "Collecting glfw (from mujoco)\n",
            "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.py39.py310.py311.py312.py313.py314-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco) (3.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (11.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (3.23.0)\n",
            "Downloading mujoco-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.py39.py310.py311.py312.py313.py314-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.10.0 mujoco-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[mujoco] mujoco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzYrpSgToOa4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import h5py\n",
        "import urllib.request\n",
        "import os\n",
        "import gymnasium as gym\n",
        "import warnings\n",
        "\n",
        "# ==========================================\n",
        "# 0. A100 SPECIFIC SETUP\n",
        "# ==========================================\n",
        "# Enable TF32 for significantly faster matrix math on Ampere (A100) GPUs\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "\n",
        "CONF = {\n",
        "    'env_name': 'Hopper-v5',\n",
        "    'context_length': 20,\n",
        "    'embed_dim': 512,\n",
        "    'n_layer': 4,\n",
        "    'n_head': 4,\n",
        "    'activation': 'relu',\n",
        "    'dropout': 0.1,\n",
        "\n",
        "    'batch_size': 4096,        # Huge Batch\n",
        "    'max_train_steps': 2500,\n",
        "    'warmup_steps': 250,\n",
        "    'lr': 6e-4,\n",
        "    'weight_decay': 1e-4,\n",
        "    'eval_interval': 100,      # Evaluate every 500 steps\n",
        "    'device': 'cuda'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gax5An2wjwPz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ==========================================\n",
        "# 1. GPU-RESIDENT DATASET\n",
        "# ==========================================\n",
        "class GPUDataset:\n",
        "    def __init__(self, context_length, data_dir='./data', scale=1000., device='cuda'):\n",
        "        self.context_length = context_length\n",
        "        self.scale = scale\n",
        "        if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
        "\n",
        "        file_name = \"hopper_medium.hdf5\"\n",
        "        file_path = os.path.join(data_dir, file_name)\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Downloading {file_name}...\")\n",
        "            urllib.request.urlretrieve(\"http://rail.eecs.berkeley.edu/datasets/offline_rl/gym_mujoco/hopper_medium.hdf5\", file_path)\n",
        "\n",
        "        with h5py.File(file_path, 'r') as f:\n",
        "            obs = f['observations'][:].astype(np.float32)\n",
        "            act = f['actions'][:].astype(np.float32)\n",
        "            rew = f['rewards'][:].astype(np.float32)\n",
        "            term = f['terminals'][:]\n",
        "\n",
        "        # Repair Boundaries\n",
        "        episode_starts, cur_len = [0], 0\n",
        "        rtg_raw = np.zeros_like(rew)\n",
        "        for i in range(len(rew)):\n",
        "            cur_len += 1\n",
        "            if term[i] or cur_len >= 1000:\n",
        "                start = episode_starts[-1]\n",
        "                rtg_raw[start:i+1] = np.cumsum(rew[start:i+1][::-1])[::-1] / scale\n",
        "                if i + 1 < len(rew):\n",
        "                    episode_starts.append(i + 1)\n",
        "                    cur_len = 0\n",
        "\n",
        "        # Normalize\n",
        "        obs_mean = obs.mean(axis=0)\n",
        "        obs_std = obs.std(axis=0) + 1e-6\n",
        "        obs = (obs - obs_mean) / obs_std\n",
        "\n",
        "        print(\"Moving dataset to GPU VRAM (Forcing Float32)...\")\n",
        "        # --- FIX: Explicitly cast to float32 to prevent Double vs Float error ---\n",
        "        self.obs = torch.from_numpy(obs).to(dtype=torch.float32, device=device)\n",
        "        self.act = torch.from_numpy(act).to(dtype=torch.float32, device=device)\n",
        "        self.rtg = torch.from_numpy(rtg_raw).to(dtype=torch.float32, device=device).unsqueeze(-1)\n",
        "\n",
        "        self.timesteps = torch.zeros(len(rew), dtype=torch.long, device=device)\n",
        "        for i in range(len(episode_starts)):\n",
        "            s = episode_starts[i]\n",
        "            e = episode_starts[i+1] if i+1 < len(episode_starts) else len(rew)\n",
        "            self.timesteps[s:e] = torch.arange(e - s, device=device)\n",
        "\n",
        "        self.episode_starts = episode_starts\n",
        "        self.state_mean = torch.from_numpy(obs_mean).to(dtype=torch.float32, device=device)\n",
        "        self.state_std = torch.from_numpy(obs_std).to(dtype=torch.float32, device=device)\n",
        "        self.act_dim = act.shape[1]\n",
        "        self.state_dim = obs.shape[1]\n",
        "\n",
        "    def get_batch(self, batch_size):\n",
        "        # Fast random sampling on GPU\n",
        "        ix = torch.randint(0, len(self.obs) - self.context_length, (batch_size,), device=self.obs.device)\n",
        "\n",
        "        ctx_idxs = ix.unsqueeze(1) + torch.arange(self.context_length, device=self.obs.device)\n",
        "\n",
        "        s = self.obs[ctx_idxs]\n",
        "        a = self.act[ctx_idxs]\n",
        "        r = self.rtg[ctx_idxs]\n",
        "        t = self.timesteps[ctx_idxs]\n",
        "\n",
        "        # Simple boundary masking\n",
        "        expected = t[:, :1] + torch.arange(self.context_length, device=self.obs.device)\n",
        "        mask = (t == expected).float()\n",
        "\n",
        "        return s, a, r, t, mask\n",
        "\n",
        "# ==========================================\n",
        "# 2. COMPILED MODEL\n",
        "# ==========================================\n",
        "class DecisionTransformer(nn.Module):\n",
        "    def __init__(self, state_dim, act_dim, hidden_size, max_length=20, max_ep_len=1000, n_layer=4, n_head=4):\n",
        "        super().__init__()\n",
        "        self.embed_timestep = nn.Embedding(max_ep_len + 1, hidden_size)\n",
        "        self.embed_return = nn.Linear(1, hidden_size)\n",
        "        self.embed_state = nn.Linear(state_dim, hidden_size)\n",
        "        self.embed_action = nn.Linear(act_dim, hidden_size)\n",
        "        self.embed_ln = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=hidden_size, nhead=n_head, dim_feedforward=4*hidden_size,\n",
        "                dropout=0.1, activation='relu', batch_first=True, norm_first=True\n",
        "            ), num_layers=n_layer\n",
        "        )\n",
        "        self.predict_action = nn.Sequential(nn.Linear(hidden_size, act_dim), nn.Tanh())\n",
        "\n",
        "    def forward(self, states, actions, returns, timesteps):\n",
        "        B, T, _ = states.shape\n",
        "        time_emb = self.embed_timestep(timesteps)\n",
        "        s_emb = self.embed_state(states) + time_emb\n",
        "        a_emb = self.embed_action(actions) + time_emb\n",
        "        r_emb = self.embed_return(returns) + time_emb\n",
        "\n",
        "        stacked = torch.stack((r_emb, s_emb, a_emb), dim=2).reshape(B, 3*T, -1)\n",
        "        stacked = self.embed_ln(stacked)\n",
        "        mask = torch.triu(torch.full((3*T, 3*T), float('-inf'), device=states.device), 1)\n",
        "\n",
        "        x = self.transformer(stacked, mask=mask, is_causal=True)\n",
        "        x = x.reshape(B, T, 3, -1)\n",
        "        return self.predict_action(x[:, :, 1, :])\n",
        "\n",
        "\n",
        "def evaluate(model, dataset, target=3600):\n",
        "    model.eval()\n",
        "    try: env = gym.make(\"Hopper-v4\")\n",
        "    except: env = gym.make(\"Hopper-v5\")\n",
        "\n",
        "    state, _ = env.reset()\n",
        "    device = CONF['device']\n",
        "\n",
        "    # --- FIX: Ensure Eval Inputs are Float32 ---\n",
        "    states = ((torch.from_numpy(state).float().to(device) - dataset.state_mean) / dataset.state_std).reshape(1, 1, -1)\n",
        "    actions = torch.zeros((1, 1, dataset.act_dim), device=device)\n",
        "    rtg = torch.tensor([[[target/1000.]]], dtype=torch.float32, device=device)\n",
        "    timesteps = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "\n",
        "    total_rew = 0\n",
        "    for t in range(1000):\n",
        "        with torch.no_grad():\n",
        "            preds = model(states[:, -20:], actions[:, -20:], rtg[:, -20:], timesteps[:, -20:])\n",
        "            action = preds[0, -1].cpu().numpy()\n",
        "\n",
        "        next_state, reward, term, trunc, _ = env.step(action)\n",
        "        total_rew += reward\n",
        "\n",
        "        new_s = ((torch.from_numpy(next_state).float().to(device) - dataset.state_mean) / dataset.state_std).reshape(1, 1, -1)\n",
        "        new_a = torch.from_numpy(action).float().to(device).reshape(1, 1, -1)\n",
        "        # --- FIX: Ensure RTG calculation stays Float32 ---\n",
        "        val = rtg[0,-1,0].item() - (reward/1000.)\n",
        "        new_r = torch.tensor([[[val]]], dtype=torch.float32, device=device)\n",
        "        new_t = torch.tensor([[t+1]], device=device).reshape(1,1)\n",
        "\n",
        "        states = torch.cat([states, new_s], dim=1)\n",
        "        actions = torch.cat([actions, new_a], dim=1)\n",
        "        rtg = torch.cat([rtg, new_r], dim=1)\n",
        "        timesteps = torch.cat([timesteps, new_t], dim=1)\n",
        "        if term or trunc: break\n",
        "\n",
        "    return 100 * total_rew / 3234.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn3vcADOmAUm",
        "outputId": "84f72c11-39ac-429d-db94-974cb4fd5005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Lightspeed Training...\n",
            "Moving dataset to GPU VRAM (Forcing Float32)...\n",
            "Compiling model... (Wait ~30s for the first step)\n",
            "Step 100/2500 | Loss: 0.1561 | Speed: 5.6 steps/sec\n",
            "--> Evaluating...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment Hopper-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Score: 0.56\n",
            "Step 200/2500 | Loss: 0.1015 | Speed: 5.2 steps/sec\n",
            "--> Evaluating...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment Hopper-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Score: 53.98\n",
            "Step 300/2500 | Loss: 0.0779 | Speed: 5.1 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 0.89\n",
            "Step 400/2500 | Loss: 0.0691 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 44.99\n",
            "Step 500/2500 | Loss: 0.0605 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 30.17\n",
            "Step 600/2500 | Loss: 0.0593 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 30.26\n",
            "Step 700/2500 | Loss: 0.0567 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 31.81\n",
            "Step 800/2500 | Loss: 0.0557 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 0.99\n",
            "Step 900/2500 | Loss: 0.0522 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 29.69\n",
            "Step 1000/2500 | Loss: 0.0534 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 30.93\n",
            "Step 1100/2500 | Loss: 0.0514 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 43.42\n",
            "Step 1200/2500 | Loss: 0.0503 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 31.17\n",
            "Step 1300/2500 | Loss: 0.0497 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 30.28\n",
            "Step 1400/2500 | Loss: 0.0497 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 61.12\n",
            "Step 1500/2500 | Loss: 0.0488 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 29.49\n",
            "Step 1600/2500 | Loss: 0.0481 | Speed: 5.4 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 81.67\n",
            "Step 1700/2500 | Loss: 0.0483 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 75.89\n",
            "Step 1800/2500 | Loss: 0.0476 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 28.18\n",
            "Step 1900/2500 | Loss: 0.0466 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 79.90\n",
            "Step 2000/2500 | Loss: 0.0453 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 98.90\n",
            "Step 2100/2500 | Loss: 0.0453 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 67.34\n",
            "Step 2200/2500 | Loss: 0.0450 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 88.22\n",
            "Step 2300/2500 | Loss: 0.0440 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 75.62\n",
            "Step 2400/2500 | Loss: 0.0431 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 29.44\n",
            "Step 2500/2500 | Loss: 0.0428 | Speed: 5.3 steps/sec\n",
            "--> Evaluating...\n",
            "    Score: 27.71\n"
          ]
        }
      ],
      "source": [
        "def train_lightspeed(conf):\n",
        "    # Re-use existing classes if available, or re-init\n",
        "    dataset = GPUDataset(conf['context_length'], device=conf['device'])\n",
        "    model = DecisionTransformer(\n",
        "        dataset.state_dim, dataset.act_dim, conf['embed_dim'], n_layer=conf['n_layer'], n_head=conf['n_head']\n",
        "    ).to(conf['device'])\n",
        "\n",
        "    print(\"Compiling model... (Wait ~30s for the first step)\")\n",
        "    model = torch.compile(model)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=conf['lr'], weight_decay=conf['weight_decay'])\n",
        "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda s: min((s+1)/conf['warmup_steps'], 1))\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "    best_score = 0\n",
        "    model.train()\n",
        "\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    for step in range(1, conf['max_train_steps'] + 1):\n",
        "        # 1. Get Batch (Instant GPU Slice)\n",
        "        s, a, r, t, mask = dataset.get_batch(conf['batch_size'])\n",
        "\n",
        "        # 2. Forward & Backward (Ampere Optimized)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            preds = model(s, a, r, t)\n",
        "            # Flatten\n",
        "            loss = torch.mean((preds.reshape(-1, dataset.act_dim)[mask.reshape(-1)>0] -\n",
        "                               a.reshape(-1, dataset.act_dim)[mask.reshape(-1)>0]) ** 2)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Logging\n",
        "        if step % 100 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            sps = step / elapsed\n",
        "            print(f\"Step {step}/{conf['max_train_steps']} | Loss: {loss.item():.4f} | Speed: {sps:.1f} steps/sec\")\n",
        "\n",
        "        # Evaluation\n",
        "        if step % conf['eval_interval'] == 0:\n",
        "            print(f\"--> Evaluating...\")\n",
        "            score = evaluate(model, dataset, target=3600)\n",
        "            print(f\"    Score: {score:.2f}\")\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                torch.save(model.state_dict(), 'best_dt_a100.pt')\n",
        "            model.train()\n",
        "\n",
        "    return model, dataset\n",
        "\n",
        "# RUN NOW\n",
        "print(\"Starting Lightspeed Training...\")\n",
        "model, dataset = train_lightspeed(CONF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4ZvyeMenC9G",
        "outputId": "bb768a97-c1e3-4889-e5bd-d646bb372b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Evaluation...\n",
            "Final Score: 80.63 ± 25.94\n"
          ]
        }
      ],
      "source": [
        "# Final Eval\n",
        "print(\"\\nFinal Evaluation...\")\n",
        "model.load_state_dict(torch.load('best_dt_a100.pt'))\n",
        "model.eval()\n",
        "scores = [evaluate(model, dataset, target=3600) for _ in range(20)]\n",
        "print(f\"Final Score: {np.mean(scores):.2f} ± {np.std(scores):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1fsZHw_qroy",
        "outputId": "3db62e04-81bd-4c4d-bb28-db79d4aa44c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Evaluation...\n",
            "Final Score: 55.38 ± 12.97\n"
          ]
        }
      ],
      "source": [
        "# Final Eval\n",
        "print(\"\\nFinal Evaluation...\")\n",
        "model.load_state_dict(torch.load('best_dt_a100.pt'))\n",
        "model.eval()\n",
        "scores = [evaluate(model, dataset, target=1800) for _ in range(20)]\n",
        "print(f\"Final Score: {np.mean(scores):.2f} ± {np.std(scores):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeSdyD8vvygo",
        "outputId": "a7ae594f-8ff5-4a45-856f-84d93b49aaaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Evaluation...\n",
            "Final Score: 26.71 ± 0.26\n"
          ]
        }
      ],
      "source": [
        "# Final Eval\n",
        "print(\"\\nFinal Evaluation...\")\n",
        "model.load_state_dict(torch.load('best_dt_a100.pt'))\n",
        "model.eval()\n",
        "scores = [evaluate(model, dataset, target=400) for _ in range(20)]\n",
        "print(f\"Final Score: {np.mean(scores):.2f} ± {np.std(scores):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The standard deviation for the 400 target is incredibly low ($\\pm 0.26$). This means the model has learned a very specific, low-energy way to \"fail safely\" or barely move to satisfy the low-reward request. In contrast, the 1000 target has a much higher standard deviation ($\\pm 1.15$), indicating that the model is exploring a wider range of behaviors to achieve the higher reward. This suggests that while the model can achieve the 400 target consistently with minimal movement, it is still learning and experimenting with different strategies to reach the 1000 target, which may require more complex or varied actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cnNpaGEv0OM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
